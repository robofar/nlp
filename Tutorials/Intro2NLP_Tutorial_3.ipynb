{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing\n",
    "\n",
    "### Tutorial 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have seen, how to tokenize a document, extract attributes from its tokens and how to create a bag of words. Today, we'll use the `CountVectorizer` and the `TfidfVectorizer` from `scikit-learn` in order to create a matrix that represents words in a document. \n",
    "\n",
    "The process of vectorizing a text is performed given the fact that most algorithms are not designed to handle raw text. Therefore, we need to represent each text document in a numerical form, so that calculations can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "Use the text provided below to create a bag of words using the `CountVectorizer` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = ['Albert Einstein, who became a Swiss citizen in 1901 and worked for years in Switzerland, is the most famous Nobel Prize winner in the sciences.',\n",
    "        'UK is too risky after the Brexit for a Gigafactory',\n",
    "        'Tesla wants to build a Gigafactory in Berlin',\n",
    "        'Brexit has made it too risky for Tesla to put a Gigafactory in the UK.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['albert', 'einstein', 'who', 'became', 'swiss', 'citizen', 'in', '1901', 'and', 'worked', 'for', 'years', 'switzerland', 'is', 'the', 'most', 'famous', 'nobel', 'prize', 'winner', 'sciences', 'uk', 'too', 'risky', 'after', 'brexit', 'gigafactory', 'tesla', 'wants', 'to', 'build', 'berlin', 'has', 'made', 'it', 'put'])\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(docs)\n",
    "print(count_vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 1 0 0 0 1 1 1 1 0 0 3 1 0 0 1 1 1 0 0 1 1 1 0 2 0 0 0 0 1 1 1 1]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we know that counting is not the only way of representing text with numbers. We can also penalize tokens that occurr very often. Why?\n",
    "\n",
    "Because in general, very frequent token sometimes are not as relevant as tokens that appear less often. For instance, if we want to retrieve documents that are relevant for a query: _The President Donald Trump_, one idea would be to retrieve all document containing all the words in the query. However, since our search retrieved still many documents, we might want to count the times that query words appear in the selected documents. But, _the_ and _president_, may still have many occurrences. Therefore, we should focus on documents that contain rather _donald trump_. But how do we get there? Calculating term frequencyâ€“inverse document frequency (tf-idf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tf-Idf**: term frequency of a token, multiplied by the inverse document frequency (log[number of documents containing a token]).\n",
    "\n",
    "- Tf: Term frequency: $\\log({count(t,d)+1}) $\n",
    "- Idf: Inverse document frequency: $\\log\\frac{|D|}{\\# d : term \\in doc}$\n",
    "\n",
    "Notice that we calculate the tf-idf for each term in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "Use the same data and the `TfidfVectorizer`, create a matrix and print features of the vectorizer. \n",
    "\n",
    "**Steps** \n",
    "Use the `?` to explore the function of the vectorizer and refer to [this link](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) for more options about the vectorizer. Increase the range of ngrams and observe the matrix. Can you see any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES:\n",
      "dict_keys(['albert', 'einstein', 'who', 'became', 'swiss', 'citizen', 'in', '1901', 'and', 'worked', 'for', 'years', 'switzerland', 'is', 'the', 'most', 'famous', 'nobel', 'prize', 'winner', 'sciences', 'uk', 'too', 'risky', 'after', 'brexit', 'gigafactory', 'tesla', 'wants', 'to', 'build', 'berlin', 'has', 'made', 'it', 'put'])\n",
      "\n",
      "MATRIX:\n",
      "[[0.20705515 0.         0.20705515 0.20705515 0.20705515 0.\n",
      "  0.         0.         0.20705515 0.20705515 0.20705515 0.13216062\n",
      "  0.         0.         0.39648185 0.16324466 0.         0.\n",
      "  0.20705515 0.20705515 0.20705515 0.         0.         0.20705515\n",
      "  0.20705515 0.20705515 0.         0.26432124 0.         0.\n",
      "  0.         0.         0.20705515 0.20705515 0.20705515 0.20705515]\n",
      " [0.         0.43314018 0.         0.         0.         0.\n",
      "  0.34149269 0.         0.         0.         0.         0.27646777\n",
      "  0.27646777 0.         0.         0.34149269 0.         0.\n",
      "  0.         0.         0.         0.         0.34149269 0.\n",
      "  0.         0.         0.         0.27646777 0.         0.34149269\n",
      "  0.34149269 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.44464184\n",
      "  0.         0.44464184 0.         0.         0.         0.\n",
      "  0.28380913 0.         0.28380913 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.35056073 0.         0.35056073 0.\n",
      "  0.         0.44464184 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2577114  0.         0.         0.         0.         0.20863959\n",
      "  0.20863959 0.32687424 0.20863959 0.         0.32687424 0.32687424\n",
      "  0.         0.         0.         0.32687424 0.2577114  0.\n",
      "  0.         0.         0.2577114  0.20863959 0.2577114  0.2577114\n",
      "  0.2577114  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1, 1),)\n",
    "X = tf_idf_vectorizer.fit_transform(docs)\n",
    "print(\"FEATURES:\")\n",
    "print(tf_idf_vectorizer.vocabulary_.keys())\n",
    "print(\"\\nMATRIX:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore these vectorizers with real data. Let's use the Yelp reviews to compare both vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "0                             Wow... Loved this place.  1\n",
       "1                                   Crust is not good.  0\n",
       "2            Not tasty and the texture was just nasty.  0\n",
       "3    Stopped by during the late May bank holiday of...  1\n",
       "4    The selection on the menu was great and so wer...  1\n",
       "..                                                 ... ..\n",
       "995  I think food should have flavor and texture an...  0\n",
       "996                           Appetite instantly gone.  0\n",
       "997  Overall I was not impressed and would not go b...  0\n",
       "998  The whole experience was underwhelming, and I ...  0\n",
       "999  Then, as if I hadn't wasted enough of my life ...  0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"yelp_polarity.txt\", sep=\"\\t\", header=None)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier\n",
    "\n",
    "In order to train any model, you need to split your data. The reason for this is that you want to test the performance of your classifier at the end. And this can't be done on the same data you train. Therefore, you need to keep a small set of data that you never use until you test. Let's create our train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_train, text_test, label_train, label_test = train_test_split(data[0], data[1], \n",
    "                                                                  test_size=0.20, \n",
    "                                                                  random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer: Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the training set to generate a feature matrix using the `CountVectorizer`. This one will be used to train our classifier.\n",
    "\n",
    "**Hint:** Please notice that you need to instantiate again a new vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polarity_count_vectorizer = CountVectorizer()\n",
    "polarity_bow_matrix = polarity_count_vectorizer.fit_transform(text_train) # determine features and transform train corpus to those features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows - samples ; Columns -> values for features\n",
    "polarity_bow_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model, we need to input the train features and their labels. In this case we will use a support vector machine (svm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1822)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_bow_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_classifier = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faris/miniconda3/envs/nlp/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_classifier.fit(polarity_bow_matrix, label_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after training we can test... But first, we need to convert our test data into numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "Vectorize your test set, in the same way we did with the train data. After vectorizing use the method `predict()` and put your test_matrix in the parentesis. This method returns a class prediction for each document in the matrix. \n",
    "\n",
    "Use NumPy to compare the original labels with the ones predicted by our model.\n",
    "\n",
    "**Hint:** Check np.sum and np.equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polarity_bow_matrix_test = polarity_count_vectorizer.transform(text_test)\n",
    "test = svm_classifier.predict(polarity_bow_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
      " 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1\n",
      " 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1\n",
      " 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1822)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_bow_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1822)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.5\n"
     ]
    }
   ],
   "source": [
    "correct_answers = np.sum(np.equal(test, label_test))\n",
    "accuracy = correct_answers / (len(test)*1.0) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Train a new model with `TfidfVectorizer`.\n",
    "\n",
    "**Hint:** Please notice that you need to instantiate a new TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
