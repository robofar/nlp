{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7e3cb3",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing\n",
    "\n",
    "### Tutorial 2\n",
    "\n",
    "---\n",
    "\n",
    "In our last session we could observe some functionality about jupyter notebooks: `?` and also `!` as well as how to `import` libraries and how the `\"hello world\"` in Python looks like. \n",
    "\n",
    "Today, we will take a look at a couple of more details and will learn to extract features from text using Pandas and Scikit Learn.\n",
    "\n",
    "Let's begin..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a8194",
   "metadata": {},
   "source": [
    "## Arrays and Hash Maps are called Lists and Dictionaries \n",
    "\n",
    "What we commonly know as an array is called in Python a list. Similarly we have also a dictionary as data structure which are like lookup tables. One interesting aspect here is that we can mix several types into this structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59e5d310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_string = \"TEST ABC\"\n",
    "my_integer = 42\n",
    "my_slice = my_string[:3]\n",
    "my_float = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec4c574a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_list = [my_string, my_integer, my_slice, my_float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91c6ef4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEST ABC', 42, 'TES', 3.5]\n"
     ]
    }
   ],
   "source": [
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab92108a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "another_list = my_string.split(\" \") + my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1c3fabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEST', 'ABC', 'TEST ABC', 42, 'TES', 3.5]\n"
     ]
    }
   ],
   "source": [
    "print(another_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f3fff08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_list.append(my_string.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46e73aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEST ABC', 42, 'TES', 3.5, ['TEST', 'ABC']]\n"
     ]
    }
   ],
   "source": [
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aa3cad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_dict = {\"a\": 1, \"b\":2, \"c\": 3, \"d\": my_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f99cb9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': ['TEST ABC', 42, 'TES', 3.5, ['TEST', 'ABC']]}\n"
     ]
    }
   ],
   "source": [
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d53c6",
   "metadata": {},
   "source": [
    "## Defining Functions\n",
    "\n",
    "Task 1: Let's say that we want a function to return always the last letter of a word in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2d810ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "this_string = \"Introduction to Natural Language Processing, second tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74037b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_last_letter(any_string):\n",
    "    # here comes your code\n",
    "    return letter_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccc97b-c968-4e1c-8fe8-75c35ae29d5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "my_letter_list = extract_last_letter(this_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b388868-94c4-48d9-98bd-bc16659e4c98",
   "metadata": {},
   "source": [
    "print(my_letter_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac73fe6",
   "metadata": {},
   "source": [
    "Create a function that returns every word in a string in lowercase and and another one for uppercase\n",
    "\n",
    "**Hint:** explore the funtions `upper` and `lower`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_lower(any_string):\n",
    "# here comes your code\n",
    "    return(lower)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(return_lower(this_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_upper(any_string):\n",
    "# here comes your code\n",
    "    return(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(return_upper(this_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32af0cd",
   "metadata": {},
   "source": [
    "## Iterating\n",
    "\n",
    "There are several ways of iterating, you can use the `enumerate()` method or you can combine `for`, `range` and the \n",
    "`length` of your type. Please make sure that you use meaningful names here. \n",
    "\n",
    "Task 3: let's create a function that returns a mapping of each word in a string and it's index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bb4fac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_word_to_index(any_string):\n",
    "    word_list = any_string.split(\" \")\n",
    "    my_mapping = {}\n",
    "    for index in range(len(word_list)):\n",
    "        my_mapping[word_list[index]] = index\n",
    "    return my_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a026ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Introduction': 0, 'to': 1, 'Natural': 2, 'Language': 3, 'Processing,': 4, 'second': 5, 'tutorial': 6}\n"
     ]
    }
   ],
   "source": [
    "print(map_word_to_index(this_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba272103",
   "metadata": {},
   "source": [
    "Now: try to explore the `enumerate()` method and write a similar function to return a list with only words with *even* indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29e997af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_even_words(any_string):\n",
    "    # here comes your code\n",
    "    mapping = []\n",
    "    word_list = any_string.split(\" \")\n",
    "    for index, value in enumerate(word_list):\n",
    "        if index % 2 == 0:\n",
    "            mapping.append(value)\n",
    "    return (mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d994620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction', 'Natural', 'Processing,', 'tutorial']\n"
     ]
    }
   ],
   "source": [
    "print(extract_even_words(this_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c5e2b",
   "metadata": {},
   "source": [
    "## Reading text files\n",
    "\n",
    "We want to know is how to read files in Python. There are several posibilities of using `open()`, which is the function to work with files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f714a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play Services bittet User um Erlaubnis für:\\n\\n* Before starting to scan for and broadcast beacons.\\n* Before providing user keys to the app for uploading to the […] server once the user has been positively diagnosed with COVID-19.\\n\\n#CoronaApp dürfte das nicht verhindern können!\n",
      "\n",
      "----\n",
      "GPT-4 and its ilk are awesome for rapid prototyping and one-offs, but at the end of the day, enterprises will deploy far smaller distilled models in production.\n",
      "\n",
      "----\n",
      "Are you wondering how large language models like ChatGPT and InstructGPT actually work? One of the secret ingredients is RLHF - Reinforcement Learning from Human Feedback.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "with open(\"tweet.txt\", 'r', encoding='utf-8') as my_file:\n",
    "    for line in my_file:\n",
    "        print(line)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f36ff-2ab4-4b7a-b0a3-82a10c20c919",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8de2d7d-a5d8-4ebd-a712-9e456005ea41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -3] Temporary failure in name resolution>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1354\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/http/client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/http/client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/http/client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/http/client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m \n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/http/client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/http/client.py:922\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/socket.py:787\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    786\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    788\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/socket.py:918\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    919\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_url\u001b[39m(url):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, urlopen(url)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m----> 9\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mread_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlittle_women_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 7\u001b[0m, in \u001b[0;36mread_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_url\u001b[39m(url):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    528\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:1383\u001b[0m, in \u001b[0;36mHTTPHandler.http_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/urllib/request.py:1357\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1355\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1358\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -3] Temporary failure in name resolution>"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "little_women_url = 'http://www.gutenberg.org/cache/epub/514/pg514.txt'\n",
    "\n",
    "def read_url(url):\n",
    "    return re.sub('\\\\s+', ' ', urlopen(url).read().decode())\n",
    "\n",
    "text = read_url(little_women_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5c83d-fc13-4bf8-a064-43df9e41e021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a7174-0151-4765-97dd-192731f83a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d7b7f-b7df-45a7-9752-07de79ee7c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a810d0-5739-40b2-b33c-87bb07ff6d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_to_i = { ch:i for i,ch in enumerate(chars) }\n",
    "i_to_s = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [s_to_i[c] for c in s]\n",
    "decode = lambda l: ''.join([i_to_s[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e4013-b575-4b9f-9646-fa750e4f2277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(encode(\"introduction to\"))\n",
    "print(decode(encode(\"introduction to\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28478d9-c1f4-4039-adea-2e9ddd89f66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's encode the text dataset and save it into a torch.Tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff977a-4398-430b-b24f-2bc0979ae2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154954a-49c5-44fb-95e8-ea9bdbf2d6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b061e-5f16-480d-9610-ae6ad0874c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc.encode(\"introduction to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8337af1-79ce-42de-8948-d88736c2ca5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc.decode([396, 17158, 311])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17be19-7cde-46dc-91c6-36f488aee9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc.encode(\"introduce To\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e85736-3f48-4c1f-b246-dc0e98a16867",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25b8d480-218a-47e2-8470-7a2e604a75fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/faris/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "007daf61-f8ca-4190-b890-4747ac070c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0ff1299-a78c-444b-8232-543e127b513e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst\n",
      "born\n",
      "wa\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"worst\"))\n",
    "print(lemmatizer.lemmatize(\"born\"))\n",
    "print(lemmatizer.lemmatize(\"was\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c446ae-2ca2-41ad-9558-99de6580765e",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557667e6-c208-4c4d-a4e2-aa8271705a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ba987-5031-434b-ad10-53478658cd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmer.stem(\"helping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0abcd",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Take the survey.csv file as an example ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ca903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here comes your code\n",
    "# Read the CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021d854-9a0a-4b8c-9175-7939481909b6",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "Pandas has two data structures that we will consider in this class, `Series` and `DataFrame`. Let's take a closer look at `Series`. At first glance, it's like playing around with a `list`. We already know what a list is and why this data structure is relevant. `Series` is also very similar, but Pandas allows index naming, making everything much easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2f55f-17d0-4c0a-8407-b393a02d0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = \"This is the first document\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483507b5-cb63-4dab-a08a-413b469c424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b51848-c08b-4357-a618-ffc36793dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd1a72-92d0-488d-aa28-2750201094e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fa272-f2e6-449c-b82b-a1bd2d7e9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"this\":0, \"is\":1, \"the\":2, \"first\":3, \"document\":4}\n",
    "my_index = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf332d02-179e-4620-b029-7a3eaaca7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83950b-f302-4a5d-bc69-050719d91492",
   "metadata": {},
   "outputs": [],
   "source": [
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0180de-5224-43bd-b64f-c2c7acbaf8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = \"this document is the second document\".split(\" \")\n",
    "series2 = pd.Series(data=[0, 1, 2, 3, 4, 5], index = list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d9470-341c-4c31-b00e-a0b0603e35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "series2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7c106-1487-4639-99de-c242e821dd0a",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "Now, let's take a look at what is a DataFrame. We can define it as several Series units that share the same index since we already know the Series data structure. Here, we will use Numpy to create a random matrix having setting also a common seed. Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61997d6f-bd4a-465f-854a-965e671ae12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b6107-e46f-40d2-b32c-2229463fef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(randn(5,4),index=[0, 1, 2, 3, 4],columns=\"A B C D\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff7afb-b0e5-4697-b974-d55c2412b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec113f0-3131-4fc4-922f-75f25094851e",
   "metadata": {},
   "source": [
    "### Indexing DataFrames\n",
    "\n",
    "Here things begin to turn a bit different. If we want to index one column, then we just call it by its name, but if we want several columns, we will need to give them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a703f9d-b9a5-467f-b5b9-0e76ba624c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82e9c6-1391-42ae-9a76-65355ca7631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[[\"C\", \"D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aba7cf-87b5-44bc-bc80-740e7d0e0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"E\"] = df1[\"A\"] * df1[\"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b6f32-2349-4368-b637-9e050a1c1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2ab6d-b565-476a-b7e0-184873da54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(\"E\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ef761-d9b2-428f-9636-b1d1fc36d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62469b20-6426-4f31-95d6-a953b2d0368f",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Pandas allows to apply a function to a `Series`, which might be sometimes super useful. Let's take a look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6e78a-6b7a-4879-a959-f34862835eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"This is the first document\",\n",
    "           \"This document is the second document\",\n",
    "           \"And this is the third one\", \n",
    "           \"Is this the first document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de13de-bcbb-4bb5-9c39-2d5c28a526a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(corpus, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166c339-5d6b-491f-a6e9-0667746d15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158bfbbe",
   "metadata": {},
   "source": [
    "Task 4: Create a function which counts the words in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7475d0-c43c-4309-b558-21720448b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(any_string):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c073e-d76e-48ca-afbb-bf467378029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to DF >> \"count_words\"\n",
    "# Your code comes here\n",
    "df2[\"count_words\"] = df2[\"text\"].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa6b03-9369-4824-9e5f-bbae53fbcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab7680-9575-4550-8c69-ec9992747606",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3a20c-8365-4402-8f68-f13af5248162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "# Your code comes here\n",
    "df2.plot.bar(x=\"text\", y=\"count_words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96ecae-5ca8-4d8e-aaa3-ef7ce0f65204",
   "metadata": {},
   "source": [
    "### Scikit-Learn: Understanding CountVectorizer\n",
    "\n",
    "The CountVectorizer is specifically used for counting words. The vectorizer part of CountVectorizer is (technically speaking!) the process of converting text into some sort of number-y thing that computers can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d15f7d1b-44fb-4b46-bf12-4e668a10b70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x25 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build the text\n",
    "text = \"\"\"The CountVectorizer is specifically used for counting words.\n",
    "The vectorizer part of CountVectorizer is (technically speaking!) the process of converting text into some sort of number-y\n",
    "thing that computers can understand.\"\"\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "matrix = vectorizer.fit_transform([text])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09457191-bc22-40fc-a0f1-9a16eb61dda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1,\n",
       "        1, 1, 1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ef3c26f-1f10-48cb-b3e8-2e8e58bfc060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can' 'computers' 'converting' 'counting' 'countvectorizer' 'for' 'into'\n",
      " 'is' 'number' 'of' 'part' 'process' 'some' 'sort' 'speaking'\n",
      " 'specifically' 'technically' 'text' 'that' 'the' 'thing' 'understand'\n",
      " 'used' 'vectorizer' 'words']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbb14588-0260-43a1-95c0-a2fe40e70bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m counts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(matrix\u001b[38;5;241m.\u001b[39mtoarray(),\n\u001b[1;32m      2\u001b[0m                       columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "counts = pd.DataFrame(matrix.toarray(),\n",
    "                      columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493d177-298a-483f-9e42-3f65dfb92d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8c2a3-e0f8-4644-a45a-916ce638c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DF and show the top 10 most common words\n",
    "counts.T.sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d99e955-a9a0-4197-83f4-51673d3e3ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best of the\n",
      "party.\"\n",
      "\n",
      "\"My dear, you flatter me. I certainly _have_ had my share of beauty, but\n",
      "I do not pretend to be any thing extraordinary now. When a woman has\n",
      "five grown up daughters, she ought to give over thinking of her own\n",
      "beauty.\"\n",
      "\n",
      "\"In such cases, a woman has not often much beauty to think of.\"\n",
      "\n",
      "\"But, my dear, you must indeed go and see Mr. Bingley when he comes into\n",
      "the neighbourhood.\"\n",
      "\n",
      "\"It is more than I engage for, I assure you.\"\n",
      "\n",
      "\"But consider your daughters. Onl\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Download the book >> Title: Pride and Prejudice\n",
    "response = requests.get('http://www.gutenberg.org/cache/epub/42671/pg42671.txt')\n",
    "text = response.text\n",
    "\n",
    "# Look at some text in the middle\n",
    "print(text[4101:4600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "647586e3-6c5c-4975-a02e-0e08911274c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6719"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often have the words \"love\" and \"hate\" been used in the book?\n",
    "#your code comes here\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform([text])\n",
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d506c60b-9c5e-4414-9dc3-7da801239652",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m counts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(matrix\u001b[38;5;241m.\u001b[39mtoarray(),\n\u001b[1;32m      2\u001b[0m                       columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names())\n\u001b[1;32m      3\u001b[0m counts\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlove\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "counts = pd.DataFrame(matrix.toarray(),\n",
    "                      columns=vectorizer.get_feature_names())\n",
    "counts\n",
    "print(counts['love'])\n",
    "print(counts['hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969b9aa-94ab-4ecd-b4eb-df9c8b947a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85727d-5e25-4faf-9091-6c0cba4602fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28569e-c039-4cf8-aec7-27c2e3834db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
